{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация изображений \n",
    "### Тестовое задание\n",
    "\n",
    "В распоряжении две папки, в одной находятся изоброжения Георгия, в другой не-Георгий. Задача обучить модель классификации Георгиев от не-Георгиев. В качестве метрики модели использована accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AvgPool2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "georges_data = pd.read_csv('/Users/albertsafin/Desktop/data/georges.csv',names=columns_name)\n",
    "non_georges_data = pd.read_csv('/Users/albertsafin/Desktop/data/non_georges.csv',names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3366 entries, 0 to 3365\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  3366 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 26.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2681 entries, 0 to 2680\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  2681 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "non_georges_data.info()\n",
    "georges_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В папке с изображением Гоергия 2681 файл, а во второй с не-Георгием - 3366 файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "georges_data['georg_pict'] = 1\n",
    "non_georges_data['georg_pict'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображение Георгия на картинке будем считать за 1, в противном случае - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = georges_data.append(non_georges_data).sample(frac=1, random_state=12345).reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6047 entries, 0 to 6046\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       6047 non-null   int64 \n",
      " 1   file_name   6047 non-null   object\n",
      " 2   georg_pict  6047 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 141.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_func(row):\n",
    "    url = row['file_name']\n",
    "    return str(Image.open(requests.get(url, stream=True).raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full['image'] = data_full.apply(image_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование ссылок на файлы в формат, который можно будет прочесть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6047 entries, 0 to 6046\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       6047 non-null   int64 \n",
      " 1   file_name   6047 non-null   object\n",
      " 2   georg_pict  6047 non-null   int64 \n",
      " 3   image       6047 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 189.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_func(row):\n",
    "    url = row['file_name']\n",
    "    i = str(row['image'])\n",
    "    urllib.request.urlretrieve(url,'/Users/albertsafin/Desktop/data/gosha/'+ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "6042    None\n",
       "6043    None\n",
       "6044    None\n",
       "6045    None\n",
       "6046    None\n",
       "Length: 6047, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.apply(download_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачал файлы для их дальнейшего использования в библиотеке keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6047 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "gen_flow = datagen.flow_from_dataframe(\n",
    "        dataframe= data_full,\n",
    "        directory= '/Users/albertsafin/Desktop/data/gosha/',\n",
    "        x_col='image',\n",
    "        y_col='georg_pict',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        validate_filenames=False,\n",
    "        seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features, target = next(gen_flow)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for i in range(10,20):\n",
    "    \n",
    "    if target[i] == 1: \n",
    "        gosha = 'да'\n",
    "    else: \n",
    "        gosha = 'нет'\n",
    "        \n",
    "    fig.add_subplot(5, 5, i+1)\n",
    "    #plt.imshow(features[i])\n",
    "    plt.title('Георгий - ' + gosha)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка изображений показала, что картинки определены правильно. (Убрал изображения, дабы не нарушать авторские права)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " data_train, data_test = train_test_split(data_full, test_size = 0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4535 entries, 4702 to 4578\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       4535 non-null   int64 \n",
      " 1   file_name   4535 non-null   object\n",
      " 2   georg_pict  4535 non-null   int64 \n",
      " 3   image       4535 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 177.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()\n",
    "#data_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделил данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1./255)\n",
    "\n",
    "    train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe= data_train,\n",
    "        directory= path,\n",
    "        x_col='image',\n",
    "        y_col='georg_pict',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        validate_filenames=False,\n",
    "        seed=12345)\n",
    "\n",
    "    return train_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1./255)\n",
    "\n",
    "    test_gen_flow = test_datagen.flow_from_dataframe(\n",
    "        dataframe= data_test,\n",
    "        directory= path,\n",
    "        x_col='image',\n",
    "        y_col='georg_pict',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        validate_filenames=False,\n",
    "        seed=12345)\n",
    "\n",
    "    return test_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)    \n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='relu')) \n",
    "    opt = Adam(lr=0.0001)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользовался слоями GlobalAveragePooling2D для усреднения информации по всему изображению, то есть получить пиксель с большим количеством каналов, Dense — полносвязный слой для классификации. Использовал также алгоритм Adam для ускорения обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, batch_size=16,\n",
    "                epochs=10, steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "    if validation_steps is None:\n",
    "        validation_steps = len(test_data)\n",
    "    model.fit(train_data,\n",
    "              validation_data=test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для загрузки данных, а также использование модели ResNet50 для обучения на обучающей выборки. В ходе тестов было выявлено, что 10 эпох будет достаточно для обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3402 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train = load_train('/Users/albertsafin/Desktop/data/gosha/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 378 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test = load_test('/Users/albertsafin/Desktop/data/gosha/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model((224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "213/213 - 745s - loss: 0.3238 - accuracy: 0.6975 - val_loss: 0.4101 - val_accuracy: 0.5899\n",
      "Epoch 2/10\n",
      "213/213 - 796s - loss: 0.1554 - accuracy: 0.8301 - val_loss: 0.4101 - val_accuracy: 0.5899\n",
      "Epoch 3/10\n",
      "213/213 - 780s - loss: 0.0872 - accuracy: 0.9150 - val_loss: 0.2330 - val_accuracy: 0.6402\n",
      "Epoch 4/10\n",
      "213/213 - 772s - loss: 0.0547 - accuracy: 0.9497 - val_loss: 0.1654 - val_accuracy: 0.8201\n",
      "Epoch 5/10\n",
      "213/213 - 723s - loss: 0.0493 - accuracy: 0.9603 - val_loss: 0.1099 - val_accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "213/213 - 702s - loss: 0.0610 - accuracy: 0.9456 - val_loss: 0.1596 - val_accuracy: 0.8122\n",
      "Epoch 7/10\n",
      "213/213 - 808s - loss: 0.0944 - accuracy: 0.9053 - val_loss: 0.1710 - val_accuracy: 0.7963\n",
      "Epoch 8/10\n",
      "213/213 - 707s - loss: 0.0744 - accuracy: 0.9292 - val_loss: 0.1085 - val_accuracy: 0.8783\n",
      "Epoch 9/10\n",
      "213/213 - 718s - loss: 0.0503 - accuracy: 0.9571 - val_loss: 0.0870 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "213/213 - 720s - loss: 0.0366 - accuracy: 0.9706 - val_loss: 0.0923 - val_accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "model_train = train_model(model,train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ИТОГ\n",
    "\n",
    "- Проверены изоброжения на адекватность. В папке с Георгием действительно изображен он.\n",
    "- Проведена предобработка файлов для дальнейшего обучения модели\n",
    "- Построена модель на основе *ResNet50*, в качестве метрики использовалась - **accuracy**, которая показала на тестовой выборке неплохой результат - **0.90**. Модель сможет определить Георгия от не-Георгия"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
